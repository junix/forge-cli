# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import List, Optional, Union, Dict, Any, Set, Tuple, cast, Literal

from openai.types.shared.metadata import Metadata
from forge_cli.common.logger import logger
from openai.types.shared.responses_model import ResponsesModel
from typing_extensions import Literal, TypeAlias

from ._models import BaseModel
from .response_error import ResponseError
from .response_output_item import ResponseOutputItem
from .reasoning import Reasoning
from .response_status import ResponseStatus
from .response_text_config import ResponseTextConfig
from .response_usage import ResponseUsage
from .annotations import AnnotationFileCitation, AnnotationURLCitation, AnnotationFilePath
from .tool import Tool
from .tool_choice_function import ToolChoiceFunction
from .tool_choice_options import ToolChoiceOptions
from .tool_choice_types import ToolChoiceTypes

__all__ = ["Response", "IncompleteDetails", "ToolChoice"]


class IncompleteDetails(BaseModel):
    reason: Optional[Literal["max_output_tokens", "content_filter"]] = None
    """The reason why the response is incomplete."""


ToolChoice: TypeAlias = Union[ToolChoiceOptions, ToolChoiceTypes, ToolChoiceFunction]


class Response(BaseModel):
    id: str
    """Unique identifier for this Response."""

    created_at: float
    """Unix timestamp (in seconds) of when this Response was created."""

    error: Optional[ResponseError] = None
    """An error object returned when the model fails to generate a Response."""

    incomplete_details: Optional[IncompleteDetails] = None
    """Details about why the response is incomplete."""

    instructions: Optional[str] = None
    """
    Inserts a system (or developer) message as the first item in the model's
    context.

    When using along with `previous_response_id`, the instructions from a previous
    response will not be carried over to the next response. This makes it simple to
    swap out system (or developer) messages in new responses.
    """

    metadata: Optional[Metadata] = None
    """Set of 16 key-value pairs that can be attached to an object.

    This can be useful for storing additional information about the object in a
    structured format, and querying for objects via API or the dashboard.

    Keys are strings with a maximum length of 64 characters. Values are strings with
    a maximum length of 512 characters.
    """

    model: ResponsesModel
    """Model ID used to generate the response, like `gpt-4o` or `o3`.

    OpenAI offers a wide range of models with different capabilities, performance
    characteristics, and price points. Refer to the
    [model guide](https://platform.openai.com/docs/models) to browse and compare
    available models.
    """

    object: Literal["response"]
    """The object type of this resource - always set to `response`."""

    output: List[ResponseOutputItem]
    """An array of content items generated by the model.

    - The length and order of items in the `output` array is dependent on the
      model's response.
    - Rather than accessing the first item in the `output` array and assuming it's
      an `assistant` message with the content generated by the model, you might
      consider using the `output_text` property where supported in SDKs.
    """

    parallel_tool_calls: bool
    """Whether to allow the model to run tool calls in parallel."""

    temperature: Optional[float] = None
    """What sampling temperature to use, between 0 and 2.

    Higher values like 0.8 will make the output more random, while lower values like
    0.2 will make it more focused and deterministic. We generally recommend altering
    this or `top_p` but not both.
    """

    tool_choice: ToolChoice
    """
    How the model should select which tool (or tools) to use when generating a
    response. See the `tools` parameter to see how to specify which tools the model
    can call.
    """

    tools: List[Tool]
    """An array of tools the model may call while generating a response.

    You can specify which tool to use by setting the `tool_choice` parameter.

    The two categories of tools you can provide the model are:

    - **Built-in tools**: Tools that are provided by OpenAI that extend the model's
      capabilities, like
      [web search](https://platform.openai.com/docs/guides/tools-web-search) or
      [file search](https://platform.openai.com/docs/guides/tools-file-search).
      Learn more about
      [built-in tools](https://platform.openai.com/docs/guides/tools).
    - **Function calls (custom tools)**: Functions that are defined by you, enabling
      the model to call your own code. Learn more about
      [function calling](https://platform.openai.com/docs/guides/function-calling).
    """

    top_p: Optional[float] = None
    """
    An alternative to sampling with temperature, called nucleus sampling, where the
    model considers the results of the tokens with top_p probability mass. So 0.1
    means only the tokens comprising the top 10% probability mass are considered.

    We generally recommend altering this or `temperature` but not both.
    """

    max_output_tokens: Optional[int] = None
    """
    An upper bound for the number of tokens that can be generated for a response,
    including visible output tokens and
    [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
    """

    previous_response_id: Optional[str] = None
    """The unique ID of the previous response to the model.

    Use this to create multi-turn conversations. Learn more about
    [conversation state](https://platform.openai.com/docs/guides/conversation-state).
    """

    reasoning: Optional[Reasoning] = None
    """**o-series models only**

    Configuration options for
    [reasoning models](https://platform.openai.com/docs/guides/reasoning).
    """

    service_tier: Optional[Literal["auto", "default", "flex"]] = None
    """Specifies the latency tier to use for processing the request.

    This parameter is relevant for customers subscribed to the scale tier service:

    - If set to 'auto', and the Project is Scale tier enabled, the system will
      utilize scale tier credits until they are exhausted.
    - If set to 'auto', and the Project is not Scale tier enabled, the request will
      be processed using the default service tier with a lower uptime SLA and no
      latency guarentee.
    - If set to 'default', the request will be processed using the default service
      tier with a lower uptime SLA and no latency guarentee.
    - If set to 'flex', the request will be processed with the Flex Processing
      service tier.
      [Learn more](https://platform.openai.com/docs/guides/flex-processing).
    - When not set, the default behavior is 'auto'.

    When this parameter is set, the response body will include the `service_tier`
    utilized.
    """

    status: Optional[ResponseStatus] = None
    """The status of the response generation.

    One of `completed`, `failed`, `in_progress`, or `incomplete`.
    """

    text: Optional[ResponseTextConfig] = None
    """Configuration options for a text response from the model.

    Can be plain text or structured JSON data. Learn more:

    - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
    - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
    """

    truncation: Optional[Literal["auto", "disabled"]] = None
    """The truncation strategy to use for the model response.

    - `auto`: If the context of this response and previous ones exceeds the model's
      context window size, the model will truncate the response to fit the context
      window by dropping input items in the middle of the conversation.
    - `disabled` (default): If a model response will exceed the context window size
      for a model, the request will fail with a 400 error.
    """

    usage: Optional[ResponseUsage] = None
    """
    Represents token usage details including input tokens, output tokens, a
    breakdown of output tokens, and the total tokens used.
    """

    user: Optional[str] = None
    """
    A unique identifier representing your end-user, which can help OpenAI to monitor
    and detect abuse.
    [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
    """

    @property
    def output_text(self) -> str:
        """Convenience property that aggregates all `output_text` items from the `output`
        list.

        If no `output_text` content blocks exist, then an empty string is returned.
        """
        texts: List[str] = []
        for output in self.output:
            if output.type == "message":
                for content in output.content:
                    if content.type == "output_text":
                        texts.append(content.text)

        return "".join(texts)

    @property
    def uncompleted_tool_calls(self) -> List[ResponseOutputItem]:
        """Returns a list of tool calls that are not completed.

        This method searches through the output items and finds any tool call items
        that have a status of "in_progress" or "incomplete", or that don't have a status set.
        """
        uncompleted_calls = []

        from .response_function_tool_call import ResponseFunctionToolCall
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_computer_tool_call import ResponseComputerToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_document_finder_tool_call import ResponseDocumentFinderToolCall

        tool_call_types = (
            ResponseFunctionToolCall,
            ResponseFileSearchToolCall,
            ResponseComputerToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
            ResponseDocumentFinderToolCall,
        )

        for output_item in self.output:
            # Check if this is a tool call type using proper type checking
            if isinstance(output_item, tool_call_types):
                # Check if this tool call is not completed
                if output_item.status is None or output_item.status in ["in_progress", "incomplete"]:
                    uncompleted_calls.append(output_item)

        return uncompleted_calls

    def last_user_message(self) -> str:
        """
        Attempts to find the last user message text within the 'output' of this Response.

        Note: Based on the current schema, 'ResponseOutputMessage' items in the
        'output' list have their 'role' attribute fixed to 'assistant'.
        Therefore, this method is unlikely to find a message with 'role == "user"'
        directly within 'self.output' and will typically return an empty string.
        User messages are usually part of the input that generated this response,
        not part of its direct output.
        """
        # Iterate in reverse to find the *last* user message if one were hypothetically present
        for output_item in reversed(self.output):
            if output_item.type == "message":
                # At this point, output_item is a ResponseOutputMessage.
                # The schema for ResponseOutputMessage has role: Literal["assistant"].
                # So, this condition (output_item.role == "user") will effectively always be false
                # with the current schema. The type ignore acknowledges this.
                if output_item.role == "user":  # type: ignore[comparison-overlap]
                    texts: List[str] = []
                    for content_part in output_item.content:
                        if content_part.type == "output_text":
                            # content_part is ResponseOutputText
                            texts.append(content_part.text)
                    return "".join(texts)  # Return text from the first "user" message found (when iterating reversed)
        return ""

    def contain_non_internal_tool_call(self) -> bool:
        """Check if the response contains any non-internal tool calls.

        This method scans through all output items to determine if there are any tool calls
        that are not system-internal tools. Internal tools include file_search, web_search,
        file_reader, and document_finder. Any other tool calls are considered user-defined
        and cannot be executed directly by the system.

        Returns:
            bool: True if the response contains at least one non-internal tool call,
                  False if all tool calls are internal or if there are no tool calls.
        """
        from .response_function_tool_call import ResponseFunctionToolCall
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_computer_tool_call import ResponseComputerToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_document_finder_tool_call import ResponseDocumentFinderToolCall
        from .response_code_interpreter_tool_call import ResponseCodeInterpreterToolCall

        # Define internal tool call types that are handled by the system
        internal_tool_types = {
            "file_search_call",
            "web_search_call",
            "file_reader_call",
            "document_finder_call",
        }

        # Tool call types that might be considered internal or have special handling
        tool_call_classes = (
            ResponseFunctionToolCall,
            ResponseFileSearchToolCall,
            ResponseComputerToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
            ResponseDocumentFinderToolCall,
            ResponseCodeInterpreterToolCall,
        )

        for output_item in self.output:
            # Check if this is a tool call type
            if isinstance(output_item, tool_call_classes):
                # For specific internal tool types, we know they're internal
                if output_item.type in internal_tool_types:
                    continue

                # For function_call type, we need to check the function name
                if output_item.type == "function_call":
                    # Check if this is an internal function based on its name
                    if output_item.name and output_item.name in {
                        "file_search",
                        "web_search",
                        "file_reader",
                        "document_finder",
                    }:
                        continue
                    # This is a user-defined function tool call
                    return True

                # Computer tool and code interpreter tool calls are considered non-internal
                # as they require special handling or user interaction
                if output_item.type in {"computer_tool_call", "code_interpreter_call"}:
                    return True

        # No non-internal tool calls found
        return False

    def install_citation_id(self) -> List:
        """Install citation IDs for all completed RAG tool call results.

        This method scans through output items to find completed or failed tool calls
        for web search, file search, and file reader operations. It then assigns
        sequential citation IDs (starting from 1) to all result items across all
        these tool calls, providing a unified citation numbering system.

        Returns:
            List: List of all citable result items with citation IDs assigned
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        citation_id = 1
        citable_items = []

        # Define the tool call types we want to process for citations
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue

            # Only process completed or failed tool calls
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                file_search_call = cast(ResponseFileSearchToolCall, output_item)
                if file_search_call.results:
                    for result in file_search_call.results:
                        result.set_citation_id(citation_id)
                        citation_id += 1
                        citable_items.append(result)

            elif output_item.type == "web_search_call":
                web_search_call = cast(ResponseFunctionWebSearch, output_item)
                if web_search_call.results:
                    for result in web_search_call.results:
                        result.set_citation_id(citation_id)
                        citation_id += 1
                        citable_items.append(result)

            elif output_item.type == "file_reader_call":
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    for result in file_reader_call.results:
                        # File reader results are Chunk objects
                        result.set_citation_id(citation_id)
                        citation_id += 1
                        citable_items.append(result)

        return citable_items

    def collect_citable_items(self) -> List:
        """Collect all citable items from web/file search tool calls and file reader tool calls.

        This method scans through output items to find completed or failed tool calls
        for web search, file search, and file reader operations. It then collects
        all result items that can be cited.

        Returns:
            List: A list of all citable result items from RAG tool calls
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        citable_items = []

        # Define the tool call types we want to process for citations
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue

            # Only process completed or failed tool calls
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                file_search_call = cast(ResponseFileSearchToolCall, output_item)
                if file_search_call.results:
                    citable_items.extend(file_search_call.results)

            elif output_item.type == "web_search_call":
                web_search_call = cast(ResponseFunctionWebSearch, output_item)
                if web_search_call.results:
                    citable_items.extend(web_search_call.results)

            elif output_item.type == "file_reader_call":
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    # File reader results are Chunk objects
                    citable_items.extend(file_reader_call.results)

        return citable_items

    def compact_retrieve_chunks(self, mode: Literal["all", "deduplicate", "nonrefed"]) -> "Response":
        """压缩检索工具返回的片段以减少上下文占用

        当存在多个工具调用（文件搜索、网络搜索、文件阅读）返回大量片段时，
        这些片段会占用大量模型上下文空间。此方法提供三种策略来缩减片段大小：

        Args:
            mode: 压缩模式
                - "all": 压缩所有片段内容，将内容替换为缩减说明并标记为不可引用
                - "deduplicate": 去除重复片段，基于文件ID+索引或URL判断重复，保留最后出现的
                - "nonrefed": 删除未被最终答案引用的片段，基于citation_id判断引用状态

        Returns:
            新的Response对象，包含压缩后的工具调用结果

        Example:
            >>> response = some_response_with_tool_calls()
            >>> compact_response = response.compact_retrieve_chunks("deduplicate")
            >>> # 去除重复片段后的响应
        """
        import re
        from typing import Dict, Set, Tuple, Any

        # Create a copy of the response to avoid modifying the original
        compacted_response = self.model_copy(deep=True)

        # Import tool call types
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        # Define RAG tool types that contain retrievable chunks
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        if mode == "all":
            # 模式1: 压缩所有片段内容
            compacted_response = compacted_response._compact_all_chunks(rag_tool_types)

        elif mode == "deduplicate":
            # 模式2: 去除重复片段
            compacted_response = compacted_response._deduplicate_chunks(rag_tool_types)

        elif mode == "nonrefed":
            # 模式3: 删除未被引用的片段
            compacted_response = compacted_response._remove_unreferenced_chunks(rag_tool_types)

        else:
            raise ValueError(f"Unsupported compaction mode: {mode}. Supported modes: 'all', 'deduplicate', 'nonrefed'")

        logger.bind(
            mode=mode, original_output_count=len(self.output), compacted_output_count=len(compacted_response.output)
        ).info("Completed chunk compaction")

        return compacted_response

    def _compact_all_chunks(self, rag_tool_types) -> "Response":
        """压缩所有检索片段的内容"""
        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue

            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                file_search_call = cast(ResponseFileSearchToolCall, output_item)
                if file_search_call.results:
                    for result in file_search_call.results:
                        # 替换内容为压缩说明
                        result.text = "【内容因上下文长度限制已压缩】"
                        # 标记为不可引用
                        if result.attributes:
                            result.attributes["segment_type"] = "compressed"
                        else:
                            result.attributes = {"segment_type": "compressed"}

            elif output_item.type == "web_search_call":
                web_search_call = cast(ResponseFunctionWebSearch, output_item)
                if web_search_call.results:
                    for result in web_search_call.results:
                        # 替换网页内容摘要
                        result.snippet = "【网页内容因上下文长度限制已压缩】"
                        # 标记为不可引用
                        if result.metadata:
                            result.metadata["segment_type"] = "compressed"
                        else:
                            result.metadata = {"segment_type": "compressed"}

            elif output_item.type == "file_reader_call":
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    for result in file_reader_call.results:
                        # 替换Chunk内容
                        result.content = "【文档内容因上下文长度限制已压缩】"
                        # 标记为不可引用
                        if result.metadata:
                            result.metadata["segment_type"] = "compressed"
                        else:
                            result.metadata = {"segment_type": "compressed"}

        return self

    def _deduplicate_chunks(self, rag_tool_types) -> "Response":
        """去除重复片段，保留最先出现的

        使用as_annotation()方法基于文档位置进行去重，而非显示citation_id。
        - 文件内容：使用file_id + segment_index (文档位置)
        - 网页内容：使用URL

        通过正向迭代确保保留最先出现的重复项，删除后续重复，
        这样可以避免回复引用"未来"片段的时间逻辑问题。
        """
        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        seen_annotations = set()

        # 正向迭代所有工具调用以保留最先出现的重复项
        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                file_search_call = cast(ResponseFileSearchToolCall, output_item)
                if file_search_call.results:
                    kept_results = []
                    # 正向处理结果列表，保留最先出现的
                    for result in file_search_call.results:
                        should_keep = True

                        # 检查是否可引用并获取annotation进行去重
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper deduplication
                            annotation = result.as_annotation()
                            if annotation and annotation in seen_annotations:
                                should_keep = False  # 重复，跳过
                            elif annotation:
                                seen_annotations.add(annotation)

                        if should_keep:
                            kept_results.append(result)

                    # 直接更新结果，保持原有顺序
                    file_search_call.results = kept_results

            elif output_item.type == "web_search_call":
                web_search_call = cast(ResponseFunctionWebSearch, output_item)
                if web_search_call.results:
                    kept_results = []
                    # 正向处理结果列表，保留最先出现的
                    for result in web_search_call.results:
                        should_keep = True

                        # 检查是否可引用并获取annotation进行去重
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper deduplication
                            annotation = result.as_annotation()
                            if annotation and annotation in seen_annotations:
                                should_keep = False  # 重复，跳过
                            elif annotation:
                                seen_annotations.add(annotation)

                        if should_keep:
                            kept_results.append(result)

                    # 直接更新结果，保持原有顺序
                    web_search_call._results = kept_results

            elif output_item.type == "file_reader_call":
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    kept_results = []
                    # 正向处理结果列表，保留最先出现的
                    for result in file_reader_call.results:
                        should_keep = True

                        # 检查是否可引用并获取annotation进行去重
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper deduplication
                            annotation = result.as_annotation()
                            if annotation and annotation in seen_annotations:
                                should_keep = False  # 重复，跳过
                            elif annotation:
                                seen_annotations.add(annotation)

                        if should_keep:
                            kept_results.append(result)

                    # 直接更新结果，保持原有顺序
                    file_reader_call._results = kept_results

        logger.bind(total_seen_annotations=len(seen_annotations)).info(
            "Completed chunk deduplication using annotation equality"
        )

        return self

    def _remove_unreferenced_chunks(self, rag_tool_types) -> "Response":
        """删除未被最终答案引用的片段

        使用get_refed_citations()获取实际被引用的citation对象，
        然后通过annotation对象的相等性比较来判断哪些结果应该保留。
        这比手动解析file_id/URL更可靠，且与去重逻辑保持一致。
        """
        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        # 获取所有实际被引用的citation annotations
        referenced_citations = self.get_cited_annotations()
        referenced_annotations_set = set(referenced_citations)

        logger.bind(
            total_referenced=len(referenced_citations),
            file_citations=len([a for a in referenced_citations if a.type == "file_citation"]),
            url_citations=len([a for a in referenced_citations if a.type == "url_citation"]),
            file_paths=len([a for a in referenced_citations if a.type == "file_path"]),
        ).info("Collected referenced citations for unreferenced chunk removal")

        # 删除未被引用的结果项
        removed_file_count = 0
        removed_web_count = 0
        removed_chunk_count = 0

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                file_search_call = cast(ResponseFileSearchToolCall, output_item)
                if file_search_call.results:
                    kept_results = []
                    for result in file_search_call.results:
                        should_keep = True

                        # 检查结果是否可引用，如果可引用则检查是否被实际引用
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper comparison
                            annotation = result.as_annotation()
                            if annotation and annotation not in referenced_annotations_set:
                                should_keep = False  # 可引用但未被引用，删除
                                removed_file_count += 1
                        # 不可引用的结果（如navigate类型）总是保留

                        if should_keep:
                            kept_results.append(result)
                    file_search_call.results = kept_results

            elif output_item.type == "web_search_call":
                web_search_call = cast(ResponseFunctionWebSearch, output_item)
                if web_search_call.results:
                    kept_results = []
                    for result in web_search_call.results:
                        should_keep = True

                        # 检查结果是否可引用，如果可引用则检查是否被实际引用
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper comparison
                            annotation = result.as_annotation()
                            if annotation and annotation not in referenced_annotations_set:
                                should_keep = False  # 可引用但未被引用，删除
                                removed_web_count += 1
                        # 不可引用的结果总是保留

                        if should_keep:
                            kept_results.append(result)
                    web_search_call._results = kept_results

            elif output_item.type == "file_reader_call":
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    kept_results = []
                    for result in file_reader_call.results:
                        should_keep = True

                        # 检查结果是否可引用，如果可引用则检查是否被实际引用
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper comparison
                            annotation = result.as_annotation()
                            if annotation and annotation not in referenced_annotations_set:
                                should_keep = False  # 可引用但未被引用，删除
                                removed_chunk_count += 1
                        # 不可引用的结果（如navigate类型）总是保留

                        if should_keep:
                            kept_results.append(result)

                    # 直接更新结果
                    file_reader_call._results = kept_results

        logger.bind(
            removed_file_results=removed_file_count,
            removed_web_results=removed_web_count,
            removed_chunks=removed_chunk_count,
            total_removed=removed_file_count + removed_web_count + removed_chunk_count,
        ).info("Completed unreferenced chunk removal using annotation equality")

        return self

    def get_cited_annotations(
        self,
    ) -> List[Union["AnnotationFileCitation", "AnnotationURLCitation", "AnnotationFilePath"]]:
        """获取Response中实际被引用的citations

        从Response的annotations字段中收集所有实际被最终答案使用的引用信息。
        这些是真正出现在输出文本中的引用，代表被成功使用的数据源。

        Returns:
            List[Union[AnnotationFileCitation, AnnotationURLCitation, AnnotationFilePath]]:
            实际被引用的citation列表

        Example:
            >>> response = some_response_with_citations()
            >>> actual_refs = response.get_refed_citations()
            >>> print(f"实际使用了 {len(actual_refs)} 个引用")
        """
        referenced_citations = []

        # 扫描所有输出项中的annotations
        for output_item in self.output:
            if output_item.type != "message":
                continue
            # 扫描消息内容中的annotations
            for content in output_item.content:
                if not content.annotations:
                    continue
                for annotation in content.annotations:
                    # 收集所有类型的citation annotations
                    if annotation.type in ["file_citation", "url_citation", "file_path"]:
                        referenced_citations.append(annotation)

        logger.bind(
            total_referenced=len(referenced_citations),
            file_citations=len([a for a in referenced_citations if a.type == "file_citation"]),
            url_citations=len([a for a in referenced_citations if a.type == "url_citation"]),
            file_paths=len([a for a in referenced_citations if a.type == "file_path"]),
        ).info("Collected actually referenced citations from Response annotations")

        return referenced_citations

    def get_candidate_annotations(self) -> List[Union["AnnotationFileCitation", "AnnotationURLCitation"]]:
        """获取所有检索到的、可引用片段的源位置注释

        遍历所有工具调用结果，对每个citable的项目调用as_annotation()方法，
        收集所有可能被引用的数据源的文档位置信息。这些基于文档段索引的注释，
        代表检索阶段获得的候选源位置，不依赖显示引用编号。

        Returns:
            List[Union[AnnotationFileCitation, AnnotationURLCitation]]:
            所有候选源注释的列表，基于文档段索引而非显示引用ID

        Example:
            >>> response = some_response_with_tool_results()
            >>> candidates = response.get_candidate_annotations()
            >>> print(f"共检索到 {len(candidates)} 个可引用数据源")
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        candidate_annotations = []

        # Define RAG tool types that contain retrievable chunks
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue
            # Only process completed or failed tool calls
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # 处理文件搜索结果
                file_search_call = cast(ResponseFileSearchToolCall, output_item)
                if file_search_call.results:
                    for result in file_search_call.results:
                        # 检查是否可引用
                        if result.is_citable():
                            # Use as_annotation() to get document-based annotation
                            annotation = result.as_annotation()
                            if annotation is not None:
                                candidate_annotations.append(annotation)

            elif output_item.type == "web_search_call":
                # 处理网页搜索结果
                web_search_call = cast(ResponseFunctionWebSearch, output_item)
                if web_search_call.results:
                    for result in web_search_call.results:
                        # 检查是否可引用
                        if result.is_citable():
                            # Use as_annotation() to get document-based annotation
                            annotation = result.as_annotation()
                            if annotation is not None:
                                candidate_annotations.append(annotation)

            elif output_item.type == "file_reader_call":
                # 处理文件阅读结果 (Chunk对象)
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    for result in file_reader_call.results:
                        # 检查是否可引用
                        if result.is_citable():
                            # Use as_annotation() to get document-based annotation
                            annotation = result.as_annotation()
                            if annotation is not None:
                                candidate_annotations.append(annotation)

        logger.bind(
            total_candidates=len(candidate_annotations),
            file_annotations=len([a for a in candidate_annotations if a.type == "file_citation"]),
            url_annotations=len([a for a in candidate_annotations if a.type == "url_citation"]),
        ).info("Collected candidate source annotations from tool results")

        return candidate_annotations

    def compact(self) -> Dict[str, Any]:
        """Remove duplicate results across all RAG tool calls.

        This method creates a new Response with deduplicated results across
        file_search, web_search, and file_reader tool calls. It uses annotation
        objects for comparison to ensure consistent deduplication logic.

        Returns:
            Dict containing compaction statistics and the compacted response:
            - response: The new Response object with deduplicated results
            - total_tool_calls_before: Total number of tool calls before compaction
            - total_tool_calls_after: Total number of tool calls after compaction
            - removed_tool_calls: Number of tool calls completely removed
            - results_by_type: Breakdown by tool type (before/after/removed counts)
            - removed_tool_call_ids: List of tool call IDs that were removed
            - kept_tool_call_ids: List of tool call IDs that were kept
            - total_results_before: Total results across all tools before
            - total_results_after: Total results across all tools after
            - total_results_removed: Total duplicate results removed
            - unique_annotations_seen: Number of unique annotations processed

        Example:
            >>> stats = response.compact()
            >>> new_response = stats["response"]
            >>> print(f"Removed {stats['total_results_removed']} duplicate results")
            >>> print(f"Removed {stats['removed_tool_calls']} empty tool calls")
        """
        from typing import cast
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        # Create a deep copy to avoid modifying the original
        compacted_response = self.model_copy(deep=True)

        # Define RAG tool types
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        # Statistics
        stats = {
            "total_tool_calls_before": 0,
            "total_tool_calls_after": 0,
            "removed_tool_calls": 0,
            "results_by_type": {
                "file_search": {"before": 0, "after": 0, "removed": 0},
                "web_search": {"before": 0, "after": 0, "removed": 0},
                "file_reader": {"before": 0, "after": 0, "removed": 0},
            },
            "removed_tool_call_ids": [],
            "kept_tool_call_ids": [],
        }

        # Track seen annotations across all tool calls
        seen_annotations = set()

        # New output list
        new_output = []

        # Process each output item
        for output_item in compacted_response.output:
            # Check if this is a RAG tool type
            if isinstance(output_item, rag_tool_types):
                # Skip if not completed
                if output_item.status not in ["completed", "failed"]:
                    new_output.append(output_item)
                    if hasattr(output_item, "id"):
                        stats["kept_tool_call_ids"].append(output_item.id)
                    continue

                stats["total_tool_calls_before"] += 1
                kept_results = []
                tool_type = None

                if output_item.type == "file_search_call":
                    tool_type = "file_search"
                    file_search_call = cast(ResponseFileSearchToolCall, output_item)

                    if file_search_call.results:
                        stats["results_by_type"][tool_type]["before"] += len(file_search_call.results)

                        for result in file_search_call.results:
                            # Only deduplicate citable results
                            if result.is_citable():
                                annotation = result.as_annotation()
                                if annotation and annotation not in seen_annotations:
                                    kept_results.append(result)
                                    seen_annotations.add(annotation)
                                else:
                                    stats["results_by_type"][tool_type]["removed"] += 1
                            else:
                                # Keep non-citable results (navigate type)
                                kept_results.append(result)

                        if kept_results:
                            file_search_call.results = kept_results
                            new_output.append(file_search_call)
                            stats["total_tool_calls_after"] += 1
                            stats["results_by_type"][tool_type]["after"] += len(kept_results)
                            stats["kept_tool_call_ids"].append(file_search_call.id)
                        else:
                            stats["removed_tool_calls"] += 1
                            stats["removed_tool_call_ids"].append(file_search_call.id)

                elif output_item.type == "web_search_call":
                    tool_type = "web_search"
                    web_search_call = cast(ResponseFunctionWebSearch, output_item)

                    if web_search_call.results:
                        stats["results_by_type"][tool_type]["before"] += len(web_search_call.results)

                        for result in web_search_call.results:
                            if result.is_citable():
                                annotation = result.as_annotation()
                                if annotation and annotation not in seen_annotations:
                                    kept_results.append(result)
                                    seen_annotations.add(annotation)
                                else:
                                    stats["results_by_type"][tool_type]["removed"] += 1
                            else:
                                kept_results.append(result)

                        if kept_results:
                            # Clear existing results and add kept results
                            web_search_call._results = kept_results
                            new_output.append(web_search_call)
                            stats["total_tool_calls_after"] += 1
                            stats["results_by_type"][tool_type]["after"] += len(kept_results)
                            stats["kept_tool_call_ids"].append(web_search_call.id)
                        else:
                            stats["removed_tool_calls"] += 1
                            stats["removed_tool_call_ids"].append(web_search_call.id)

                elif output_item.type == "file_reader_call":
                    tool_type = "file_reader"
                    file_reader_call = cast(ResponseFunctionFileReader, output_item)

                    if file_reader_call.results:
                        stats["results_by_type"][tool_type]["before"] += len(file_reader_call.results)

                        for result in file_reader_call.results:
                            if result.is_citable():
                                annotation = result.as_annotation()
                                if annotation and annotation not in seen_annotations:
                                    kept_results.append(result)
                                    seen_annotations.add(annotation)
                                else:
                                    stats["results_by_type"][tool_type]["removed"] += 1
                            else:
                                kept_results.append(result)

                        if kept_results:
                            file_reader_call._results = kept_results
                            new_output.append(file_reader_call)
                            stats["total_tool_calls_after"] += 1
                            stats["results_by_type"][tool_type]["after"] += len(kept_results)
                            stats["kept_tool_call_ids"].append(file_reader_call.id)
                        else:
                            stats["removed_tool_calls"] += 1
                            stats["removed_tool_call_ids"].append(file_reader_call.id)
            else:
                # Keep non-RAG tool calls as-is
                new_output.append(output_item)

        # Update the response with new output
        compacted_response.output = new_output

        # Calculate totals
        stats["total_results_before"] = sum(t["before"] for t in stats["results_by_type"].values())
        stats["total_results_after"] = sum(t["after"] for t in stats["results_by_type"].values())
        stats["total_results_removed"] = sum(t["removed"] for t in stats["results_by_type"].values())
        stats["unique_annotations_seen"] = len(seen_annotations)

        # Add response to stats
        stats["response"] = compacted_response

        # Log summary
        logger.bind(
            total_removed=stats["total_results_removed"],
            removed_tool_calls=stats["removed_tool_calls"],
            unique_annotations=stats["unique_annotations_seen"],
        ).info("Completed response compaction with cross-tool deduplication")

        return stats

    def deduplicate(self) -> "Response":
        """Create a deduplicated copy of this response.

        Convenience method that returns just the deduplicated response
        without the statistics.

        Returns:
            Response: New response with deduplicated results
        """
        return self.compact()["response"]

    def has_duplicates(self) -> bool:
        """Check if this response contains duplicate results.

        Returns:
            bool: True if duplicates exist, False otherwise
        """
        stats = self.compact()
        return stats["total_results_removed"] > 0

    def get_duplication_stats(self) -> Dict[str, Any]:
        """Get duplication statistics without creating a new response.

        Returns:
            Dict: Statistics about duplicates without the response object
        """
        stats = self.compact()
        stats.pop("response")  # Remove the response object
        return stats

    def brief_repr(self, algorithm: Literal["truncate", "smart", "hierarchical"] = "smart") -> "Response":
        """Create a brief representation of the response with shortened string values.

        This method creates a clone of the response where long strings are abbreviated
        to reduce noise in logs and debugging output. Three algorithms are available:

        1. "truncate": Simple string truncation showing start and end
           - Shows first 40 chars and last 30 chars of strings
           - Good for general purpose logging

        2. "smart": Context-aware truncation preserving key information
           - Preserves complete short strings
           - Shows more context for important fields (text, content, results)
           - Summarizes tool results and chunks intelligently

        3. "hierarchical": Structured view with smart summaries
           - Shows response structure with counts
           - Summarizes tool calls and results
           - Best for understanding response flow

        Args:
            algorithm: The algorithm to use for brevity ("truncate", "smart", "hierarchical")

        Returns:
            New Response with abbreviated content

        Example:
            >>> brief = response.brief_repr("smart")
            >>> print(brief.model_dump_json(indent=2))  # Readable JSON
        """
        if algorithm == "truncate":
            return self._brief_repr_truncate()
        elif algorithm == "smart":
            return self._brief_repr_smart()
        elif algorithm == "hierarchical":
            return self._brief_repr_hierarchical()
        else:
            raise ValueError(f"Unknown algorithm: {algorithm}")

    def _brief_repr_truncate(self) -> "Response":
        """Simple truncation algorithm: show start and end of strings."""

        def truncate_value(value: Any, start_len: int = 40, end_len: int = 30) -> Any:
            if isinstance(value, str) and len(value) > start_len + end_len + 10:
                return f"{value[:start_len]} ... {value[-end_len:]}"
            elif isinstance(value, dict):
                return {k: truncate_value(v, start_len, end_len) for k, v in value.items()}
            elif isinstance(value, list):
                # Limit list length for display
                if len(value) > 10:
                    truncated_items = [truncate_value(item, start_len, end_len) for item in value[:5]]
                    truncated_items.append(f"... {len(value) - 7} more items ...")
                    truncated_items.extend([truncate_value(item, start_len, end_len) for item in value[-2:]])
                    return truncated_items
                else:
                    return [truncate_value(item, start_len, end_len) for item in value]
            else:
                return value

        # Create a deep copy and truncate
        response_data = self.model_dump()
        truncated_data = truncate_value(response_data)
        return Response.model_validate(truncated_data)

    def _brief_repr_smart(self) -> "Response":
        """Smart context-aware truncation preserving important information."""
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader

        def smart_truncate(value: Any, context: str = "", depth: int = 0) -> Any:
            # Don't truncate short strings
            if isinstance(value, str):
                if len(value) <= 100:
                    return value

                # Different truncation rules based on context
                if context in ["text", "content", "snippet", "output_text"]:
                    # More generous for main content
                    if len(value) > 200:
                        return f"{value[:100]} ... [{len(value) - 130} chars] ... {value[-30:]}"
                    return value
                elif context in ["arguments", "query", "instructions"]:
                    # Show more of arguments/queries for debugging
                    if len(value) > 150:
                        return f"{value[:80]} ... {value[-50:]}"
                    return value
                elif context == "id":
                    # Shorten IDs
                    if len(value) > 12:
                        return f"{value[:8]}..."
                    return value
                else:
                    # Default truncation
                    if len(value) > 80:
                        return f"{value[:40]} ... {value[-30:]}"
                    return value

            elif isinstance(value, dict):
                result = {}
                for k, v in value.items():
                    # Special handling for known fields
                    if k == "results" and isinstance(v, list) and len(v) > 3:
                        # Summarize long result lists
                        result[k] = [
                            smart_truncate(v[0], k, depth + 1),
                            f"... {len(v) - 2} more results ...",
                            smart_truncate(v[-1], k, depth + 1),
                        ]
                    elif k == "output" and isinstance(v, list) and len(v) > 5:
                        # Summarize output items
                        result[k] = [
                            smart_truncate(v[0], k, depth + 1),
                            smart_truncate(v[1], k, depth + 1) if len(v) > 1 else None,
                            f"... {len(v) - 3} more items ...",
                            smart_truncate(v[-1], k, depth + 1),
                        ]
                        result[k] = [item for item in result[k] if item is not None]
                    else:
                        result[k] = smart_truncate(v, k, depth + 1)
                return result

            elif isinstance(value, list):
                if len(value) > 10 and depth > 1:
                    # Collapse long lists at deeper levels
                    return [
                        smart_truncate(value[0], context, depth + 1),
                        f"... {len(value) - 2} more items ...",
                        smart_truncate(value[-1], context, depth + 1),
                    ]
                else:
                    return [smart_truncate(item, context, depth + 1) for item in value]

            else:
                return value

        # Process with smart truncation
        response_data = self.model_dump()
        smart_data = smart_truncate(response_data)
        return Response.model_validate(smart_data)

    def _brief_repr_hierarchical(self) -> "Response":
        """Hierarchical view with structured summaries."""
        from .response_output_message import ResponseOutputMessage
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_tool_call import ResponseFunctionToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_document_finder_tool_call import ResponseDocumentFinderToolCall
        from .response_computer_tool_call import ResponseComputerToolCall
        from .response_code_interpreter_tool_call import ResponseCodeInterpreterToolCall

        # Create a simplified copy
        brief_data = {
            "id": self.id[:8] + "..." if len(self.id) > 12 else self.id,
            "created_at": self.created_at,
            "model": self.model,
            "object": self.object,
            "status": self.status,
        }

        # Add error if present
        if self.error:
            brief_data["error"] = {
                "type": self.error.type,
                "message": self.error.message[:100] + "..." if len(self.error.message) > 100 else self.error.message,
            }

        # Summarize output items
        brief_output = []
        message_count = 0
        tool_call_counts = {}

        for item in self.output:
            if item.type == "message":
                message_count += 1
                # Summarize message content
                content_summary = f"[{len(item.content)} content items]"
                if hasattr(item, "content") and item.content:
                    # Count content types
                    content_types = {}
                    for content in item.content:
                        ctype = getattr(content, "type", "unknown")
                        content_types[ctype] = content_types.get(ctype, 0) + 1
                    content_summary = f"[{', '.join(f'{count} {typ}' for typ, count in content_types.items())}]"

                brief_output.append({"type": "message", "role": item.role, "content": content_summary})

            elif hasattr(item, "type") and "tool_call" in item.type or item.type == "function_call":
                # Count tool calls by type
                tool_type = item.type
                tool_call_counts[tool_type] = tool_call_counts.get(tool_type, 0) + 1

                # Create a brief representation
                brief_item = {
                    "type": tool_type,
                    "id": item.id[:8] + "..."
                    if hasattr(item, "id") and len(item.id) > 12
                    else getattr(item, "id", "N/A"),
                    "status": getattr(item, "status", "N/A"),
                }

                # Add result count for specific tool types
                if hasattr(item, "results") and item.results:
                    brief_item["results"] = f"[{len(item.results)} results]"
                elif hasattr(item, "name"):
                    brief_item["name"] = item.name

                brief_output.append(brief_item)

        # Create summary
        output_summary = []
        if message_count > 0:
            output_summary.append(f"{message_count} messages")
        for tool_type, count in tool_call_counts.items():
            output_summary.append(f"{count} {tool_type}")

        brief_data["output"] = f"[{', '.join(output_summary)}]" if output_summary else "[]"
        brief_data["output_items"] = brief_output[:10]  # Show first 10 items
        if len(self.output) > 10:
            brief_data["output_items"].append(f"... {len(self.output) - 10} more items ...")

        # Add key properties
        brief_data["output_text_length"] = len(self.output_text)
        brief_data["parallel_tool_calls"] = self.parallel_tool_calls

        # Add tool info
        if self.tools:
            brief_data["tools"] = f"[{len(self.tools)} tools defined]"
            tool_names = [tool.name if hasattr(tool, "name") else tool.type for tool in self.tools[:3]]
            if len(self.tools) > 3:
                tool_names.append(f"... {len(self.tools) - 3} more")
            brief_data["tool_names"] = tool_names

        # Add usage if present
        if self.usage:
            brief_data["usage"] = {
                "total_tokens": self.usage.total_tokens,
                "input_tokens": self.usage.input_tokens,
                "output_tokens": self.usage.output_tokens,
            }

        # Add other important fields if present
        if self.temperature is not None:
            brief_data["temperature"] = self.temperature
        if self.max_output_tokens is not None:
            brief_data["max_output_tokens"] = self.max_output_tokens
        if self.instructions:
            brief_data["instructions"] = (
                self.instructions[:100] + "..." if len(self.instructions) > 100 else self.instructions
            )

        # Create a new Response with simplified data
        # Since we've heavily modified the structure, we'll use model_validate with minimal required fields
        minimal_response = Response(
            id=brief_data["id"],
            created_at=self.created_at,
            model=self.model,
            object=self.object,
            output=[],  # Empty output, we'll show summary separately
            parallel_tool_calls=self.parallel_tool_calls,
            tool_choice=self.tool_choice,
            tools=self.tools[:3] if len(self.tools) > 3 else self.tools,  # Limit tools shown
        )

        # Add a custom brief summary as metadata
        if not minimal_response.metadata:
            minimal_response.metadata = {}
        minimal_response.metadata["brief_summary"] = brief_data

        return minimal_response
