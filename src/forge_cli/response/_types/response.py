# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import Any, Literal, TypeAlias, Union, cast

from openai.types.shared.metadata import Metadata
from openai.types.shared.responses_model import ResponsesModel

from forge_cli.common.logger import logger

from ._models import BaseModel
from .annotations import AnnotationFileCitation, AnnotationFilePath, AnnotationURLCitation
from .reasoning import Reasoning
from .response_error import ResponseError
from .response_output_item import ResponseOutputItem
from .response_status import ResponseStatus
from .response_text_config import ResponseTextConfig
from .response_usage import ResponseUsage
from .tool import Tool
from .tool_choice_function import ToolChoiceFunction
from .tool_choice_options import ToolChoiceOptions
from .tool_choice_types import ToolChoiceTypes

__all__ = ["Response", "IncompleteDetails", "ToolChoice"]


class IncompleteDetails(BaseModel):
    reason: Literal["max_output_tokens", "content_filter"] | None = None
    """The reason why the response is incomplete."""


ToolChoice: TypeAlias = ToolChoiceOptions | ToolChoiceTypes | ToolChoiceFunction


class Response(BaseModel):
    id: str
    """Unique identifier for this Response."""

    created_at: float
    """Unix timestamp (in seconds) of when this Response was created."""

    error: ResponseError | None = None
    """An error object returned when the model fails to generate a Response."""

    incomplete_details: IncompleteDetails | None = None
    """Details about why the response is incomplete."""

    instructions: str | None = None
    """
    Inserts a system (or developer) message as the first item in the model's
    context.

    When using along with `previous_response_id`, the instructions from a previous
    response will not be carried over to the next response. This makes it simple to
    swap out system (or developer) messages in new responses.
    """

    metadata: Metadata | None = None
    """Set of 16 key-value pairs that can be attached to an object.

    This can be useful for storing additional information about the object in a
    structured format, and querying for objects via API or the dashboard.

    Keys are strings with a maximum length of 64 characters. Values are strings with
    a maximum length of 512 characters.
    """

    model: ResponsesModel
    """Model ID used to generate the response, like `gpt-4o` or `o3`.

    OpenAI offers a wide range of models with different capabilities, performance
    characteristics, and price points. Refer to the
    [model guide](https://platform.openai.com/docs/models) to browse and compare
    available models.
    """

    object: Literal["response"]
    """The object type of this resource - always set to `response`."""

    output: list[ResponseOutputItem]
    """An array of content items generated by the model.

    - The length and order of items in the `output` array is dependent on the
      model's response.
    - Rather than accessing the first item in the `output` array and assuming it's
      an `assistant` message with the content generated by the model, you might
      consider using the `output_text` property where supported in SDKs.
    """

    parallel_tool_calls: bool
    """Whether to allow the model to run tool calls in parallel."""

    temperature: float | None = None
    """What sampling temperature to use, between 0 and 2.

    Higher values like 0.8 will make the output more random, while lower values like
    0.2 will make it more focused and deterministic. We generally recommend altering
    this or `top_p` but not both.
    """

    tool_choice: ToolChoice
    """
    How the model should select which tool (or tools) to use when generating a
    response. See the `tools` parameter to see how to specify which tools the model
    can call.
    """

    tools: list[Tool]
    """An array of tools the model may call while generating a response.

    You can specify which tool to use by setting the `tool_choice` parameter.

    The two categories of tools you can provide the model are:

    - **Built-in tools**: Tools that are provided by OpenAI that extend the model's
      capabilities, like
      [web search](https://platform.openai.com/docs/guides/tools-web-search) or
      [file search](https://platform.openai.com/docs/guides/tools-file-search).
      Learn more about
      [built-in tools](https://platform.openai.com/docs/guides/tools).
    - **Function calls (custom tools)**: Functions that are defined by you, enabling
      the model to call your own code. Learn more about
      [function calling](https://platform.openai.com/docs/guides/function-calling).
    """

    top_p: float | None = None
    """
    An alternative to sampling with temperature, called nucleus sampling, where the
    model considers the results of the tokens with top_p probability mass. So 0.1
    means only the tokens comprising the top 10% probability mass are considered.

    We generally recommend altering this or `temperature` but not both.
    """

    max_output_tokens: int | None = None
    """
    An upper bound for the number of tokens that can be generated for a response,
    including visible output tokens and
    [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
    """

    previous_response_id: str | None = None
    """The unique ID of the previous response to the model.

    Use this to create multi-turn conversations. Learn more about
    [conversation state](https://platform.openai.com/docs/guides/conversation-state).
    """

    reasoning: Reasoning | None = None
    """**o-series models only**

    Configuration options for
    [reasoning models](https://platform.openai.com/docs/guides/reasoning).
    """

    service_tier: Literal["auto", "default", "flex"] | None = None
    """Specifies the latency tier to use for processing the request.

    This parameter is relevant for customers subscribed to the scale tier service:

    - If set to 'auto', and the Project is Scale tier enabled, the system will
      utilize scale tier credits until they are exhausted.
    - If set to 'auto', and the Project is not Scale tier enabled, the request will
      be processed using the default service tier with a lower uptime SLA and no
      latency guarentee.
    - If set to 'default', the request will be processed using the default service
      tier with a lower uptime SLA and no latency guarentee.
    - If set to 'flex', the request will be processed with the Flex Processing
      service tier.
      [Learn more](https://platform.openai.com/docs/guides/flex-processing).
    - When not set, the default behavior is 'auto'.

    When this parameter is set, the response body will include the `service_tier`
    utilized.
    """

    status: ResponseStatus | None = None
    """The status of the response generation.

    One of `completed`, `failed`, `in_progress`, or `incomplete`.
    """

    text: ResponseTextConfig | None = None
    """Configuration options for a text response from the model.

    Can be plain text or structured JSON data. Learn more:

    - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
    - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
    """

    truncation: Literal["auto", "disabled"] | None = None
    """The truncation strategy to use for the model response.

    - `auto`: If the context of this response and previous ones exceeds the model's
      context window size, the model will truncate the response to fit the context
      window by dropping input items in the middle of the conversation.
    - `disabled` (default): If a model response will exceed the context window size
      for a model, the request will fail with a 400 error.
    """

    usage: ResponseUsage | None = None
    """
    Represents token usage details including input tokens, output tokens, a
    breakdown of output tokens, and the total tokens used.
    """

    user: str | None = None
    """
    A unique identifier representing your end-user, which can help OpenAI to monitor
    and detect abuse.
    [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
    """

    @property
    def output_text(self) -> str:
        """Convenience property that aggregates all `output_text` items from the `output`
        list.

        If no `output_text` content blocks exist, then an empty string is returned.
        """
        texts: list[str] = []
        for output in self.output:
            if output.type == "message":
                for content in output.content:
                    if content.type == "output_text":
                        texts.append(content.text)

        return "".join(texts)

    def contain_non_internal_tool_call(self) -> bool:
        """Check if the response contains any non-internal tool calls.

        This method scans through all output items to determine if there are any tool calls
        that are not system-internal tools. Internal tools include file_search, web_search,
        file_reader, and list_documents. Any other tool calls are considered user-defined
        and cannot be executed directly by the system.

        Returns:
            bool: True if the response contains at least one non-internal tool call,
                  False if all tool calls are internal or if there are no tool calls.
        """
        from .response_code_interpreter_tool_call import ResponseCodeInterpreterToolCall
        from .response_computer_tool_call import ResponseComputerToolCall
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_tool_call import ResponseFunctionToolCall
        from .response_function_web_search import ResponseFunctionWebSearch
        from .response_list_documents_tool_call import ResponseListDocumentsToolCall

        # Define internal tool call types that are handled by the system
        internal_tool_types = {
            "file_search_call",
            "web_search_call",
            "file_reader_call",
            "list_documents_call",
        }

        # Tool call types that might be considered internal or have special handling
        tool_call_classes = (
            ResponseFunctionToolCall,
            ResponseFileSearchToolCall,
            ResponseComputerToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
            ResponseListDocumentsToolCall,
            ResponseCodeInterpreterToolCall,
        )

        for output_item in self.output:
            # Check if this is a tool call type
            if isinstance(output_item, tool_call_classes):
                # For specific internal tool types, we know they're internal
                if output_item.type in internal_tool_types:
                    continue

                # For function_call type, we need to check the function name
                if output_item.type == "function_call":
                    # Check if this is an internal function based on its name
                    if output_item.name and output_item.name in {
                        "file_search",
                        "web_search",
                        "file_reader",
                        "list_documents",
                    }:
                        continue
                    # This is a user-defined function tool call
                    return True

                # Computer tool and code interpreter tool calls are considered non-internal
                # as they require special handling or user interaction
                if output_item.type in {"computer_tool_call", "code_interpreter_call"}:
                    return True

        # No non-internal tool calls found
        return False

    def install_citation_id(self) -> list:
        """Install citation IDs for all completed RAG tool call results.

        This method scans through output items to find completed or failed tool calls
        for web search, file search, and file reader operations. It then assigns
        sequential citation IDs (starting from 1) to all result items across all
        these tool calls, providing a unified citation numbering system.

        Returns:
            List: List of all citable result items with citation IDs assigned
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        citation_id = 1
        citable_items = []

        # Define the tool call types we want to process for citations
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue

            # Only process completed or failed tool calls
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # File search results are not directly accessible from tool call
                pass

            elif output_item.type == "web_search_call":
                # Web search results are not directly accessible from tool call
                pass

            elif output_item.type == "file_reader_call":
                # File reader results are not directly accessible from tool call
                pass

        return citable_items

    def collect_citable_items(self) -> list:
        """Collect all citable items from web/file search tool calls and file reader tool calls.

        This method scans through output items to find completed or failed tool calls
        for web search, file search, and file reader operations. It then collects
        all result items that can be cited.

        Returns:
            List: A list of all citable result items from RAG tool calls
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        citable_items = []

        # Define the tool call types we want to process for citations
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue

            # Only process completed or failed tool calls
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # File search results are not directly accessible from tool call
                pass

            elif output_item.type == "web_search_call":
                # Web search results are not directly accessible from tool call
                pass

            elif output_item.type == "file_reader_call":
                # File reader results are not directly accessible from tool call
                pass

        return citable_items

    def compact_retrieve_chunks(self, mode: Literal["all", "deduplicate", "nonrefed"]) -> "Response":
        """压缩检索工具返回的片段以减少上下文占用

        当存在多个工具调用（文件搜索、网络搜索、文件阅读）返回大量片段时，
        这些片段会占用大量模型上下文空间。此方法提供三种策略来缩减片段大小：

        Args:
            mode: 压缩模式
                - "all": 压缩所有片段内容，将内容替换为缩减说明并标记为不可引用
                - "deduplicate": 去除重复片段，基于文件ID+索引或URL判断重复，保留最后出现的
                - "nonrefed": 删除未被最终答案引用的片段，基于citation_id判断引用状态

        Returns:
            新的Response对象，包含压缩后的工具调用结果

        Example:
            >>> response = some_response_with_tool_calls()
            >>> compact_response = response.compact_retrieve_chunks("deduplicate")
            >>> # 去除重复片段后的响应
        """

        # Create a copy of the response to avoid modifying the original
        compacted_response = self.model_copy(deep=True)

        # Import tool call types
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        # Define RAG tool types that contain retrievable chunks
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        if mode == "all":
            # 模式1: 压缩所有片段内容
            compacted_response = compacted_response._compact_all_chunks(rag_tool_types)

        elif mode == "deduplicate":
            # 模式2: 去除重复片段
            compacted_response = compacted_response._deduplicate_chunks(rag_tool_types)

        elif mode == "nonrefed":
            # 模式3: 删除未被引用的片段
            compacted_response = compacted_response._remove_unreferenced_chunks(rag_tool_types)

        else:
            raise ValueError(f"Unsupported compaction mode: {mode}. Supported modes: 'all', 'deduplicate', 'nonrefed'")

        logger.bind(
            mode=mode, original_output_count=len(self.output), compacted_output_count=len(compacted_response.output)
        ).info("Completed chunk compaction")

        return compacted_response

    def _compact_all_chunks(self, rag_tool_types) -> "Response":
        """压缩所有检索片段的内容"""

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue

            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # File search results are not directly accessible from tool call
                pass

            elif output_item.type == "web_search_call":
                # Web search results are not directly accessible from tool call
                pass

            elif output_item.type == "file_reader_call":
                # File reader results are not directly accessible from tool call
                pass

        return self

    def _deduplicate_chunks(self, rag_tool_types) -> "Response":
        """去除重复片段，保留最先出现的

        使用as_annotation()方法基于文档位置进行去重，而非显示citation_id。
        - 文件内容：使用file_id + segment_index (文档位置)
        - 网页内容：使用URL

        通过正向迭代确保保留最先出现的重复项，删除后续重复，
        这样可以避免回复引用"未来"片段的时间逻辑问题。
        """
        from .response_function_file_reader import ResponseFunctionFileReader

        seen_annotations = set()

        # 正向迭代所有工具调用以保留最先出现的重复项
        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # File search results are not directly accessible from tool call
                pass

            elif output_item.type == "web_search_call":
                # Web search results are not directly accessible from tool call
                pass

            elif output_item.type == "file_reader_call":
                file_reader_call = cast(ResponseFunctionFileReader, output_item)
                if file_reader_call.results:
                    kept_results = []
                    # 正向处理结果列表，保留最先出现的
                    for result in file_reader_call.results:
                        should_keep = True

                        # 检查是否可引用并获取annotation进行去重
                        if result.is_citable():
                            # Use as_annotation() which uses document segment index for proper deduplication
                            annotation = result.as_annotation()
                            if annotation and annotation in seen_annotations:
                                should_keep = False  # 重复，跳过
                            elif annotation:
                                seen_annotations.add(annotation)

                        if should_keep:
                            kept_results.append(result)

                    # 直接更新结果，保持原有顺序
                    file_reader_call._results = kept_results

        logger.bind(total_seen_annotations=len(seen_annotations)).info(
            "Completed chunk deduplication using annotation equality"
        )

        return self

    def _remove_unreferenced_chunks(self, rag_tool_types) -> "Response":
        """删除未被最终答案引用的片段

        使用get_refed_citations()获取实际被引用的citation对象，
        然后通过annotation对象的相等性比较来判断哪些结果应该保留。
        这比手动解析file_id/URL更可靠，且与去重逻辑保持一致。
        """

        # 获取所有实际被引用的citation annotations
        referenced_citations = self.get_cited_annotations()
        referenced_annotations_set = set(referenced_citations)

        logger.bind(
            total_referenced=len(referenced_citations),
            file_citations=len([a for a in referenced_citations if a.type == "file_citation"]),
            url_citations=len([a for a in referenced_citations if a.type == "url_citation"]),
            file_paths=len([a for a in referenced_citations if a.type == "file_path"]),
        ).info("Collected referenced citations for unreferenced chunk removal")

        # 删除未被引用的结果项
        removed_file_count = 0
        removed_web_count = 0
        removed_chunk_count = 0

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # File search results are not directly accessible from tool call
                pass

            elif output_item.type == "web_search_call":
                # Web search results are not directly accessible from tool call
                pass

            elif output_item.type == "file_reader_call":
                # File reader results are not directly accessible from tool call
                pass

        logger.bind(
            removed_file_results=removed_file_count,
            removed_web_results=removed_web_count,
            removed_chunks=removed_chunk_count,
            total_removed=removed_file_count + removed_web_count + removed_chunk_count,
        ).info("Completed unreferenced chunk removal using annotation equality")

        return self

    def get_cited_annotations(
        self,
    ) -> list[Union["AnnotationFileCitation", "AnnotationURLCitation", "AnnotationFilePath"]]:
        """获取Response中实际被引用的citations

        从Response的annotations字段中收集所有实际被最终答案使用的引用信息。
        这些是真正出现在输出文本中的引用，代表被成功使用的数据源。

        Returns:
            List[Union[AnnotationFileCitation, AnnotationURLCitation, AnnotationFilePath]]:
            实际被引用的citation列表

        Example:
            >>> response = some_response_with_citations()
            >>> actual_refs = response.get_refed_citations()
            >>> print(f"实际使用了 {len(actual_refs)} 个引用")
        """
        referenced_citations = []

        # 扫描所有输出项中的annotations
        for output_item in self.output:
            if output_item.type != "message":
                continue
            # 扫描消息内容中的annotations
            for content in output_item.content:
                if not content.annotations:
                    continue
                for annotation in content.annotations:
                    # 收集所有类型的citation annotations
                    if annotation.type in ["file_citation", "url_citation", "file_path"]:
                        referenced_citations.append(annotation)

        logger.bind(
            total_referenced=len(referenced_citations),
            file_citations=len([a for a in referenced_citations if a.type == "file_citation"]),
            url_citations=len([a for a in referenced_citations if a.type == "url_citation"]),
            file_paths=len([a for a in referenced_citations if a.type == "file_path"]),
        ).info("Collected actually referenced citations from Response annotations")

        return referenced_citations

    def get_candidate_annotations(self) -> list[Union["AnnotationFileCitation", "AnnotationURLCitation"]]:
        """获取所有检索到的、可引用片段的源位置注释

        遍历所有工具调用结果，对每个citable的项目调用as_annotation()方法，
        收集所有可能被引用的数据源的文档位置信息。这些基于文档段索引的注释，
        代表检索阶段获得的候选源位置，不依赖显示引用编号。

        Returns:
            List[Union[AnnotationFileCitation, AnnotationURLCitation]]:
            所有候选源注释的列表，基于文档段索引而非显示引用ID

        Example:
            >>> response = some_response_with_tool_results()
            >>> candidates = response.get_candidate_annotations()
            >>> print(f"共检索到 {len(candidates)} 个可引用数据源")
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        candidate_annotations = []

        # Define RAG tool types that contain retrievable chunks
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        for output_item in self.output:
            if not isinstance(output_item, rag_tool_types):
                continue
            # Only process completed or failed tool calls
            if output_item.status not in ["completed", "failed"]:
                continue

            if output_item.type == "file_search_call":
                # File search results are not directly accessible from tool call
                pass

            elif output_item.type == "web_search_call":
                # Web search results are not directly accessible from tool call
                pass

            elif output_item.type == "file_reader_call":
                # File reader results are not directly accessible from tool call
                pass

        logger.bind(
            total_candidates=len(candidate_annotations),
            file_annotations=len([a for a in candidate_annotations if a.type == "file_citation"]),
            url_annotations=len([a for a in candidate_annotations if a.type == "url_citation"]),
        ).info("Collected candidate source annotations from tool results")

        return candidate_annotations

    def compact(self) -> dict[str, Any]:
        """Remove duplicate results across all RAG tool calls.

        This method creates a new Response with deduplicated results across
        file_search, web_search, and file_reader tool calls. It uses annotation
        objects for comparison to ensure consistent deduplication logic.

        Returns:
            Dict containing compaction statistics and the compacted response:
            - response: The new Response object with deduplicated results
            - total_tool_calls_before: Total number of tool calls before compaction
            - total_tool_calls_after: Total number of tool calls after compaction
            - removed_tool_calls: Number of tool calls completely removed
            - results_by_type: Breakdown by tool type (before/after/removed counts)
            - removed_tool_call_ids: List of tool call IDs that were removed
            - kept_tool_call_ids: List of tool call IDs that were kept
            - total_results_before: Total results across all tools before
            - total_results_after: Total results across all tools after
            - total_results_removed: Total duplicate results removed
            - unique_annotations_seen: Number of unique annotations processed

        Example:
            >>> stats = response.compact()
            >>> new_response = stats["response"]
            >>> print(f"Removed {stats['total_results_removed']} duplicate results")
            >>> print(f"Removed {stats['removed_tool_calls']} empty tool calls")
        """
        from .response_file_search_tool_call import ResponseFileSearchToolCall
        from .response_function_file_reader import ResponseFunctionFileReader
        from .response_function_web_search import ResponseFunctionWebSearch

        # Create a deep copy to avoid modifying the original
        compacted_response = self.model_copy(deep=True)

        # Define RAG tool types
        rag_tool_types = (
            ResponseFileSearchToolCall,
            ResponseFunctionWebSearch,
            ResponseFunctionFileReader,
        )

        # Statistics
        stats = {
            "total_tool_calls_before": 0,
            "total_tool_calls_after": 0,
            "removed_tool_calls": 0,
            "results_by_type": {
                "file_search": {"before": 0, "after": 0, "removed": 0},
                "web_search": {"before": 0, "after": 0, "removed": 0},
                "file_reader": {"before": 0, "after": 0, "removed": 0},
            },
            "removed_tool_call_ids": [],
            "kept_tool_call_ids": [],
        }

        # Track seen annotations across all tool calls
        seen_annotations = set()

        # New output list
        new_output = []

        # Process each output item
        for output_item in compacted_response.output:
            # Check if this is a RAG tool type
            if isinstance(output_item, rag_tool_types):
                # Skip if not completed
                if output_item.status not in ["completed", "failed"]:
                    new_output.append(output_item)
                    if hasattr(output_item, "id"):
                        stats["kept_tool_call_ids"].append(output_item.id)
                    continue

                stats["total_tool_calls_before"] += 1
                kept_results = []
                tool_type = None

                if output_item.type == "file_search_call":
                    tool_type = "file_search"
                    # File search results are not directly accessible from tool call
                    # Keep the tool call as-is
                    new_output.append(output_item)
                    stats["total_tool_calls_after"] += 1
                    if hasattr(output_item, "id"):
                        stats["kept_tool_call_ids"].append(output_item.id)

                elif output_item.type == "web_search_call":
                    # Web search results are not directly accessible from tool call
                    pass

                elif output_item.type == "file_reader_call":
                    # File reader results are not directly accessible from tool call
                    pass
            else:
                # Keep non-RAG tool calls as-is
                new_output.append(output_item)

        # Update the response with new output
        compacted_response.output = new_output

        # Calculate totals
        stats["total_results_before"] = sum(t["before"] for t in stats["results_by_type"].values())
        stats["total_results_after"] = sum(t["after"] for t in stats["results_by_type"].values())
        stats["total_results_removed"] = sum(t["removed"] for t in stats["results_by_type"].values())
        stats["unique_annotations_seen"] = len(seen_annotations)

        # Add response to stats
        stats["response"] = compacted_response

        # Log summary
        logger.bind(
            total_removed=stats["total_results_removed"],
            removed_tool_calls=stats["removed_tool_calls"],
            unique_annotations=stats["unique_annotations_seen"],
        ).info("Completed response compaction with cross-tool deduplication")

        return stats

    def deduplicate(self) -> "Response":
        """Create a deduplicated copy of this response.

        Convenience method that returns just the deduplicated response
        without the statistics.

        Returns:
            Response: New response with deduplicated results
        """
        return self.compact()["response"]
